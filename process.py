import json
import re
from pathlib import Path
from typing import List, Union

from dragon_baseline import DragonBaseline

from llm_extractinator import extractinate


class DragonSubmission(DragonBaseline):
    def __init__(self, **kwargs):
        # Example of how to adapt the DRAGON baseline to use a different model
        """
        Adapt the DRAGON baseline to use the joeranbosma/dragon-roberta-base-mixed-domain model.
        Note: when changing the model, update the Dockerfile to pre-download that model.
        """
        super().__init__(**kwargs)
        pass

    def custom_text_cleaning(
        self, text: Union[str, List[str]]
    ) -> Union[str, List[str]]:
        """
        Perform custom text cleaning on the input text.

        Args:
            text (Union[str, List[str]]): The input text to be cleaned. It can be a string or a list of strings.

        Returns:
            Union[str, List[str]]: The cleaned text. If the input is a string, the cleaned string is returned.
            If the input is a list of strings, a list of cleaned strings is returned.

        """
        if isinstance(text, str):
            # Remove HTML tags and URLs:
            text = re.sub(r"<.*?>", "", text)
            text = re.sub(r"http\S+", "", text)

            return text
        else:
            # If text is a list, apply the function to each element
            return [self.custom_text_cleaning(t) for t in text]

    def process(self):
        """
        Override the process method to use llm_extractinator for predictions.
        """
        self.load()
        self.validate()
        self.analyze()
        self.preprocess()
        self.setup_folder_structure()
        self.extract_predictions()
        self.postprocess()
        self.verify_predictions()

    def setup_folder_structure(self):
        """
        Create the necessary folders for the LLM to generate predictions.
        """
        basepath = Path("/opt/app")
        basepath.mkdir(exist_ok=True)
        (basepath / "data").mkdir(exist_ok=True)
        (basepath / "output").mkdir(exist_ok=True)
        (basepath / "tasks").mkdir(exist_ok=True)

        self.df_test.to_json(basepath / "data" / "test.json", orient="records")

    def extract_predictions(self):
        """
        Use the pre-trained LLM to generate predictions for the test data.

        Args:
            df (DataFrame): The test dataframe containing input data.

        Returns:
            List: Predictions generated by the LLM.
        """
        basepath = Path("/opt/app")
        self.task_id = re.search(r"\d{3}", self.task.task_name).group(0)

        extractinate(
            task_id=self.task_id,
            model_name="mistral-nemo",
            num_examples=0,
            max_context_len=8192,
            num_predict=512,
            translate=False,
            data_dir=basepath / "data",
            output_dir=basepath / "output",
            task_dir=basepath / "tasks",
            n_runs=1,
            verbose=False,
            run_name="run",
        )

    def postprocess(self):
        """
        Post-process the predictions generated by the LLM.
        """

        def print_processing_message(task_id: str) -> None:
            """
            Prints a message indicating the task being processed.
            """
            print(f"Post-processing Task{task_id}...")

        def save_json(data: List, filepath: Path) -> None:
            """
            Save the data to a JSON file.
            """
            with open(filepath, "w") as f:
                json.dump(data, f)

        datapath = Path("/opt/app/output/run/")
        filepath = self.test_predictions_path

        for folder in datapath.iterdir():
            if self.task_id in folder.name:
                datapath = folder
                break

        with open(datapath, "r") as file:
            data = json.load(file)

        task_id = f"{int(self.task_id):03}"

        binary_class_ids = [1, 2, 3, 4, 5, 6, 7, 8, 101]
        binary_class_ids = [f"{int(class_id):03}" for class_id in binary_class_ids]

        multi_class_ids = [9, 10, 11, 12, 13, 14, 102]
        multi_class_ids = [f"{int(class_id):03}" for class_id in multi_class_ids]

        single_regression_ids = [19, 20, 21, 22, 23]
        single_regression_ids = [
            f"{int(class_id):03}" for class_id in single_regression_ids
        ]

        if task_id in binary_class_ids:
            print_processing_message(task_id)
            try:
                for example in data:
                    if example["label"] == "True":
                        example["label"] = True
                    if example["label"] == "False":
                        example["label"] = False
                    example["single_label_binary_classification"] = example.pop("label")
            except KeyError:
                print(f"Task {task_id} does not contain 'label' key.")
                pass
            save_json(data=data, filepath=filepath)
        elif task_id in multi_class_ids:
            print_processing_message(task_id)
            try:
                for example in data:
                    example["single_label_multi_class_classification"] = example.pop(
                        "label"
                    )
            except KeyError:
                print(f"Task {task_id} does not contain 'label' key.")
                pass
            save_json(data=data, filepath=filepath)
        elif task_id in single_regression_ids:
            print_processing_message(task_id)
            try:
                for example in data:
                    example["single_label_regression"] = example.pop("label")
            except KeyError:
                print(f"Task {task_id} does not contain 'label' key.")
                pass
            save_json(data=data, filepath=filepath)
        elif task_id == "015":
            print_processing_message(task_id)
            try:
                for example in data:
                    example["multi_label_binary_classification"] = [
                        example.pop("biopsy"),
                        example.pop("cancer"),
                        example.pop("high_grade_dysplasia"),
                        example.pop("hyperplastic_polyps"),
                        example.pop("low_grade_dysplasia"),
                        example.pop("non_informative"),
                        example.pop("serrated_polyps"),
                    ]
            except KeyError:
                print(f"Task {task_id} does not contain the correct keys.")
                pass
            save_json(data=data, filepath=filepath)
        elif task_id == "016":
            print_processing_message(task_id)
            try:
                for example in data:
                    example["multi_label_binary_classification"] = [
                        example.pop("lesion_1"),
                        example.pop("lesion_2"),
                        example.pop("lesion_3"),
                        example.pop("lesion_4"),
                        example.pop("lesion_5"),
                    ]
            except KeyError:
                print(f"Task {task_id} does not contain the correct keys.")
                pass
            save_json(data=data, filepath=filepath)
        elif task_id == "017":
            print_processing_message(task_id)
            try:
                for example in data:
                    example["multi_label_multi_class_classification"] = [
                        example.pop("attenuation"),
                        example.pop("location"),
                    ]
            except KeyError:
                print(f"Task {task_id} does not contain the correct keys.")
                pass
            save_json(data=data, filepath=filepath)
        elif task_id == "018":
            print_processing_message(task_id)
            try:
                for example in data:
                    example["multi_label_multi_class_classification"] = [
                        example.pop("left"),
                        example.pop("right"),
                    ]
            except KeyError:
                print(f"Task {task_id} does not contain the correct keys.")
                pass
            save_json(data=data, filepath=filepath)
        elif task_id == "024":
            print_processing_message(task_id)
            try:
                for example in data:
                    example["multi_label_regression"] = [
                        example.pop("lesion_1"),
                        example.pop("lesion_2"),
                        example.pop("lesion_3"),
                        example.pop("lesion_4"),
                        example.pop("lesion_5"),
                    ]
            except KeyError:
                print(f"Task {task_id} does not contain the correct keys.")
                pass
            save_json(data=data, filepath=filepath)
        elif task_id == "025":
            print_processing_message(task_id)
            try:
                pass
            except KeyError:
                print(f"Task {task_id} does not contain the correct keys.")
                pass
            save_json(data=data, filepath=filepath)


if __name__ == "__main__":
    DragonSubmission().process()
